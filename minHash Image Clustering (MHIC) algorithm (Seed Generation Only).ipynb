{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# minHash Image Clustering (MHIC) algorithm (Seed Generation Only)\n",
    "\n",
    "Implementation based on \n",
    "* [Large-Scale Discovery of Spatially Related Images](ieeexplore.ieee.org/iel5/34/4359286/05235143.pdf) by Ondrej Chum and Jiri Matas\n",
    "* [Scalable Near Identical Image and Shot Detection - Microsoft](https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/civr2007.pdf) by Ondrej Chum, James Philbin, Michael Isard, Andrew Zisserman\n",
    "\n",
    "## Purpose\n",
    "\n",
    "If we see a similar image cluster as a connected compoenent, images are vertex. \n",
    "We have to find edges to get image cluster. minHash can be used to find subset of the edges quickly. \n",
    "\n",
    "Afterward, you may use image retrieval system to complete the connected component. \n",
    "\n",
    "\n",
    "## Requirements\n",
    "\n",
    "* Visual words index list for each image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from src import mhic_seed_generation\n",
    "\n",
    "mhic_seed_generation.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "\n",
    "work_dir = './output'\n",
    "\n",
    "output_similar_pair_result = 'similar_pair.pkl'\n",
    "output_ransac_result = 'similar_pair_ransac.pkl'\n",
    "\n",
    "similar_pairs = pickle.load(open(os.path.join(work_dir, output_similar_pair_result), 'rb'))\n",
    "rasac_result = pickle.load(open(os.path.join(work_dir, output_ransac_result), 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMAGE_DIR = \"./data/oxford5k_images\"\n",
    "IMAGE_DIR = \"./data/oxford/oxford5k/images\"\n",
    "similar_pairs.sort(key=lambda x: x[2], reverse=True)\n",
    "for image_cluster, score, num_inlier in similar_pairs:\n",
    "    print(\"pair: {}, score: {}\".format(image_cluster, score, num_inlier))\n",
    "    show_image_cluster(IMAGE_DIR, image_cluster)\n",
    "    print('\\n') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "def show_image_cluster(image_dir, image_names):\n",
    "    \"\"\"\n",
    "    show image cluster for oxford 5k dataset\n",
    "    \"\"\"\n",
    "    # Visualize images assigned to this cluster    \n",
    "    from PIL import Image\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    imgs = []    \n",
    "    for image_name in image_names:\n",
    "        image_name = image_name.replace(\"oxc1_\", \"\") + \".jpg\"\n",
    "        image_path = os.path.join(image_dir, image_name)\n",
    "        img = Image.open(image_path)\n",
    "        imgs.append(img)            \n",
    "        \n",
    "    cols = 5\n",
    "    imgs = imgs[:cols]\n",
    "    plt.figure(figsize=(20, 5))\n",
    "    for i, img in enumerate(imgs):\n",
    "        plt.subplot(1, cols, i + 1)\n",
    "        plt.imshow(img)\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "# IMAGE_DIR = \"./data/oxford5k_images\"\n",
    "IMAGE_DIR = \"./data/oxford/oxford5k/images\"\n",
    "sample_count = 10\n",
    "print(\"Sampling from irrelevant images.\")\n",
    "target_seq = similar_pairs[:count_irr]\n",
    "k = min(sample_count, len(target_seq))\n",
    "for image_cluster, score in random.sample(target_seq, k):\n",
    "    print(\"pair: {}, score: {}\".format(image_cluster, score))\n",
    "    show_image_cluster(IMAGE_DIR, image_cluster)\n",
    "    print('\\n')    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "print(\"Sampling from similar images.\")\n",
    "target_seq = similar_pairs[count_irr:count_irr+count_sim]\n",
    "k = min(sample_count, len(target_seq))\n",
    "target_seq.sort(key=lambda x: x[1], reverse=True)\n",
    "for image_cluster, score in target_seq:\n",
    "    print(\"pair: {}, score: {}\".format(image_cluster, score))\n",
    "    show_image_cluster(IMAGE_DIR, image_cluster)\n",
    "    print('\\n')    \n",
    "    \n",
    "print(\"Sampling from near-duplicates images.\")\n",
    "target_seq = similar_pairs[count_irr+count_sim:]\n",
    "target_seq.sort(key=lambda x: x[1], reverse=True)\n",
    "k = min(sample_count, len(target_seq))\n",
    "for image_cluster, score in random.sample(target_seq, k):\n",
    "    print(\"pair: {}, score: {}\".format(image_cluster, score))\n",
    "    show_image_cluster(IMAGE_DIR, image_cluster)\n",
    "    print('\\n')    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
