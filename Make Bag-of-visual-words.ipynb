{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Bag-of-visual-words\n",
    "\n",
    "* Load Image's descriptor for all images. \n",
    "* Find corresponding visual word index for each descriptor. \n",
    "* Save list of visual word index."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For Oxford 5k dataset, You can use already provided visual words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count_descriptor: 16334970\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Oxford 5k dataset provides already converted visual words. We could use this one\n",
    "import os \n",
    "import pickle\n",
    "\n",
    "oxf5k_visualword_dir = './data/word_oxc1_hesaff_sift_16M_1M'\n",
    "work_dir = \"./oxfk5_provided\"\n",
    "if not os.path.exists(work_dir):\n",
    "    os.mkdir(work_dir)\n",
    "\n",
    "filelist = os.listdir(oxf5k_visualword_dir)\n",
    "filelist.sort()\n",
    "# print(filelist)\n",
    "# for parent_dir, _, files in os.walk(oxf5k_visualword_dir):\n",
    "#     print(files)\n",
    "\n",
    "bow_dict = {}\n",
    "count_descriptor = 0\n",
    "image_feature_count_info = []\n",
    "for filename in filelist:\n",
    "    filepath = os.path.join(oxf5k_visualword_dir, filename)\n",
    "    image_name = filename.replace(\".txt\", \"\")    \n",
    "    visual_words = []\n",
    "    with open(filepath) as f:\n",
    "        lines = list(map(lambda x: x.strip(), f.readlines()[2:])) # ignore first two lines        \n",
    "        for l in lines:\n",
    "            val = l.split(\" \")\n",
    "            visual_word_index = int(val[0])-1 # This data use 1 to 1,000,000. convert to zero-based so 0 to 999,999  \n",
    "            visual_words.append(visual_word_index)\n",
    "            # print('{} descriptor {}'.format(filename, l))\n",
    "        count_descriptor = count_descriptor + len(lines)\n",
    "    image_feature_count_info.append((image_name, len(visual_words)))\n",
    "    bow_dict[image_name] = sorted(visual_words)\n",
    "    # break\n",
    "# print('bow_dict:', bow_dict)\n",
    "print('count_descriptor:', count_descriptor)\n",
    "\n",
    "pickle.dump(bow_dict, open(os.path.join(work_dir, 'bow_dict_word_oxc1_hesaff_sift_16M_1M_pretrained.pkl'), 'wb'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Or we could make a new one from provided feature info for Oxford 5k\n",
    "\n",
    "Oxford 5k dataset already provide SIFT descriptors, and visual words info. \n",
    "The file containing SIFT descriptor does not have information of how many descriptors are belong to which image. \n",
    "This missing information can be found in visual words info file. \n",
    "After we get the assignment relationship, we can successfully get dictionary of key: image name, values: list of descriptos.\n",
    "\n",
    "## Requirements\n",
    "\n",
    "* SIFT descriptor containing file. `feat_oxc1_hesaff_sift.bin`\n",
    "* Image filename order for the above file `order.txt`\n",
    "* Bag-of-words informatino file `word_oxc1_hesaff_sift_16M_1M`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For oxford 5k dataset, it may be possible to recover the \"Image name and its associated 128d descriptors\"\n",
    "from utils.oxf5k_feature_reader import feature_reader\n",
    "\n",
    "# Frist, read all 128d descriptor of image.\n",
    "feature_bin_path = \"./data/feature/feat_oxc1_hesaff_sift.bin\"\n",
    "all_features = feature_reader(feature_bin_path)\n",
    "print('num of 128d descriptors in oxf5k: ', len(all_features))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the order of filenames related to above features. Refer README in http://www.robots.ox.ac.uk/~vgg/data/oxbuildings/README2.txt\n",
    "import os\n",
    "feature_bin_filename_order_path = \"./data/feature/order.txt\"\n",
    "with open(feature_bin_filename_order_path) as f:\n",
    "    filenames = list(map(lambda x: x.strip(), f.readlines()))\n",
    "\n",
    "BOW_INFO_DIR='./data/word_oxc1_hesaff_sift_16M_1M'\n",
    "image_feature_count_info = []\n",
    "for image_name in filenames:\n",
    "    filename = image_name + \".txt\"\n",
    "    with open(os.path.join(BOW_INFO_DIR, filename)) as f:\n",
    "        header_text = list(map(lambda x: x.strip(), f.readlines()[:2]))        \n",
    "        num_descriptor = int(header_text[1])        \n",
    "        image_feature_count_info.append((image_name, num_descriptor))    \n",
    "    \n",
    "print('image_feature_count_info[:5]:',image_feature_count_info[:5])\n",
    "\n",
    "# Check compatibility of name order\n",
    "for idx, val in enumerate(image_feature_count_info):\n",
    "    name_from_vw, _ = val\n",
    "    if name_from_vw == filenames[idx]:\n",
    "        continue\n",
    "    else:\n",
    "        print(idx, name_from_vw, filenames[idx])\n",
    "print(\"compatibility check done\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "image_descriptor_dict = {} # key: image_name, value: 2d numpy array of shape (num_descriptor, dim_descriptor)\n",
    "start_idx = 0\n",
    "for image_name, num_descriptor in image_feature_count_info:\n",
    "    val = np.array(all_features[start_idx:(start_idx+num_descriptor)], dtype=np.uint8)\n",
    "    image_descriptor_dict[image_name] = val\n",
    "    \n",
    "    start_idx += num_descriptor\n",
    "    # break\n",
    "# print('image_descriptor_dict:', image_descriptor_dict)\n",
    "with open('image_descriptor_dict_oxc1_hesaff_sift_16M.pkl', 'wb') as f:\n",
    "    pickle.dump(image_descriptor_dict, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# After you prepared everything, run below code\n",
    "\n",
    "## Preparation list\n",
    "\n",
    "* (image, descriptor_list) tuple\n",
    "* centroids\n",
    "\n",
    "TODO: determine design choice when we use encoding such as Product Quantization. \n",
    "1. keep centroid as PQ code. It means we always have to keep encoder parts. \n",
    "2. keep centroid as original vector. It means there is room for additional error when we assign each descriptor to the nearest centroid. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load image descriptor dictionary, and assign each descriptor to visual words\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pqkmeans\n",
    "from tqdm import tqdm\n",
    "from multiprocessing import Pool, TimeoutError\n",
    "\n",
    "image_descriptor_dict_path = 'image_descriptor_dict_oxc1_hesaff_sift_16M.pkl'\n",
    "\n",
    "# You should use matching encoder that was used to do PQk-means clustering. \n",
    "# encoder_save_path = 'pqencoder_100k_random_sample_from_16M.pkl'\n",
    "# cluster_center_save_path = 'clustering_centers_in_pqcode_numpy.npy'\n",
    "\n",
    "# encoder_save_path = 'pqencoder_1000k_random_sample_from_16M.pkl'\n",
    "# cluster_center_save_path = 'clustering_centers_numpy_16M_feature_1000k_coodebook_131k_cluster.npy'\n",
    "\n",
    "encoder_save_path = 'pqencoder_1000k_8_sub_random_sample_from_16M.pkl'\n",
    "cluster_center_save_path = 'clustering_centers_numpy_16M_feature_1000k_coodebook_8_sub_131k_cluster.npy'\n",
    "\n",
    "output_bow_dict_save_path = 'bow_dict_word_oxc1_hesaff_sift_16M_1M_8_sub_handmade.pkl'\n",
    "\n",
    "# encoder_save_path = 'encoder.pkl'\n",
    "# cluster_center_save_path = 'clustering_centers_numpy.npy'\n",
    "    \n",
    "# For PQ-kmeans clustering, we first convert query to PQ codes. \n",
    "with open(encoder_save_path, 'rb') as f:\n",
    "    encoder = pickle.load(f)\n",
    "clustering_centers_in_pqcode_numpy = np.load(cluster_center_save_path)\n",
    "# print('cluster centers shape: ', clustering_centers_in_pqcode_numpy.shape)\n",
    "\n",
    "k = clustering_centers_in_pqcode_numpy.shape[0]\n",
    "print('number of clusters:', k)\n",
    "engine = pqkmeans.clustering.PQKMeans(encoder=encoder, k=k, iteration=1, verbose=False, init_centers=clustering_centers_in_pqcode_numpy)\n",
    "    \n",
    "bow_dict = {}\n",
    "\n",
    "\n",
    "def run(val):\n",
    "    image_name, descriptors = val\n",
    "    data_points_pqcodes = encoder.transform(descriptors)\n",
    "    # print('num_descriptors:', len(data_points_pqcodes))\n",
    "    # print('num_descriptors shape:', data_points_pqcodes.shape)\n",
    "    # TODO: speedup by using pq-kmeans assignment step. \n",
    "    # visual_words = get_assigned_center_index(data_points_pqcodes, clustering_centers_in_pqcode_numpy)\n",
    "    visual_words = engine.predict(data_points_pqcodes) # Fast assignment step. \n",
    "    \n",
    "    return (image_name, list(set(list(visual_words))))\n",
    "    \n",
    "if __name__ == \"__main__\":    \n",
    "    \n",
    "    with open(image_descriptor_dict_path, 'rb') as f:\n",
    "        # key: image_name, value: 2d numpy array of shape (num_descriptor, dim_descriptor)\n",
    "        image_descriptor_dict = pickle.load(f) \n",
    "    # print('num images:', len(image_descriptor_dict))\n",
    "    \n",
    "    pool = Pool(processes=20) # start 20 worker processes\n",
    "    # print same numbers in arbitrary order\n",
    "    for image_name, bow in tqdm(pool.imap_unordered(run, image_descriptor_dict.items()), total=len(image_descriptor_dict)):        \n",
    "        bow_dict[image_name] = bow\n",
    "        \n",
    "    print('done')\n",
    "    pickle.dump(bow_dict, open(output_bow_dict_save_path, 'wb'))\n",
    "    \n",
    "# Timing: 24min for 5062 images with 16M features. 100k leanred codebook with 4 subspaces. 2^17 clusters. \n",
    "# Timing: 38min for 5062 images with 16M features. 1M leanred codebook with 8 subspaces. 2^17 clusters. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Or we could make a new one\n",
    "\n",
    "## Requirements\n",
    "\n",
    "* Image name and its associated 128d descriptors\n",
    "* visual words assigner\n",
    "    * For a given 128d descriptor, it tells index of visual words. \n",
    "    * After you ran k-means clustering, you could use it to get nearest centroid's id\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
