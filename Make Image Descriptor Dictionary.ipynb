{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Image Descriptor Dictionary\n",
    "\n",
    "We want to have data structure that dic['image_name'] returns tuple of (keypoints, descriptors) where \n",
    "\n",
    "* keypoints is 2d numpy array with rows represent (x, y, a, b, c)\n",
    "* descriptors in 2d numpay array with size of (num_descriptor, descriptor_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (Check it again. I Doubt it now after testing) Or we could make a new one from provided feature info for Oxford 5k\n",
    "\n",
    "Oxford 5k dataset already provide SIFT descriptors, and visual words info. \n",
    "The file containing SIFT descriptor does not have information of how many descriptors are belong to which image. \n",
    "This missing information can be found in visual words info file. \n",
    "After we get the assignment relationship, we can successfully get dictionary of key: image name, values: list of descriptos.\n",
    "\n",
    "## Requirements\n",
    "\n",
    "* SIFT descriptor containing file. `feat_oxc1_hesaff_sift.bin`\n",
    "* Image filename order for the above file `order.txt`\n",
    "* Bag-of-words informatino file `word_oxc1_hesaff_sift_16M_1M`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For oxford 5k dataset, it may be possible to recover the \"Image name and its associated 128d descriptors\"\n",
    "from utils.oxf5k_feature_reader import feature_reader\n",
    "\n",
    "# Frist, read all 128d descriptor of image.\n",
    "feature_bin_path = \"./data/feature/feat_oxc1_hesaff_sift.bin\"\n",
    "all_features = feature_reader(feature_bin_path)\n",
    "print('num of 128d descriptors in oxf5k: ', len(all_features))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the order of filenames related to above features. Refer README in http://www.robots.ox.ac.uk/~vgg/data/oxbuildings/README2.txt\n",
    "import os\n",
    "feature_bin_filename_order_path = \"./data/feature/order.txt\"\n",
    "with open(feature_bin_filename_order_path) as f:\n",
    "    filenames = list(map(lambda x: x.strip(), f.readlines()))\n",
    "\n",
    "BOW_INFO_DIR='./data/word_oxc1_hesaff_sift_16M_1M'\n",
    "image_feature_count_info = []\n",
    "for image_name in filenames:\n",
    "    filename = image_name + \".txt\"\n",
    "    with open(os.path.join(BOW_INFO_DIR, filename)) as f:\n",
    "        header_text = list(map(lambda x: x.strip(), f.readlines()[:2]))        \n",
    "        num_descriptor = int(header_text[1])        \n",
    "        image_feature_count_info.append((image_name, num_descriptor))    \n",
    "    \n",
    "print('image_feature_count_info[:5]:',image_feature_count_info[:5])\n",
    "\n",
    "# Check compatibility of name order\n",
    "for idx, val in enumerate(image_feature_count_info):\n",
    "    name_from_vw, _ = val\n",
    "    if name_from_vw == filenames[idx]:\n",
    "        continue\n",
    "    else:\n",
    "        print(idx, name_from_vw, filenames[idx])\n",
    "print(\"compatibility check done\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "image_descriptor_dict = {} # key: image_name, value: 2d numpy array of shape (num_descriptor, dim_descriptor)\n",
    "start_idx = 0\n",
    "for image_name, num_descriptor in image_feature_count_info:\n",
    "    val = np.array(all_features[start_idx:(start_idx+num_descriptor)], dtype=np.uint8)\n",
    "    image_descriptor_dict[image_name] = val\n",
    "    \n",
    "    start_idx += num_descriptor\n",
    "    # break\n",
    "# print('image_descriptor_dict:', image_descriptor_dict)\n",
    "with open('image_descriptor_dict_oxc1_hesaff_sift_16M.pkl', 'wb') as f:\n",
    "    pickle.dump(image_descriptor_dict, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read from hessaff.sift files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/5062 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|          | 2/5062 [00:00<04:44, 17.78it/s]\u001b[A\n",
      "  0%|          | 6/5062 [00:00<03:19, 25.40it/s]\u001b[A\n",
      "  0%|          | 13/5062 [00:00<02:20, 35.99it/s]\u001b[A\n",
      "  0%|          | 21/5062 [00:00<01:52, 44.97it/s]\u001b[A\n",
      "  1%|          | 26/5062 [00:00<01:55, 43.52it/s]\u001b[A\n",
      "  1%|          | 34/5062 [00:00<01:50, 45.38it/s]\u001b[A\n",
      "  1%|          | 42/5062 [00:00<01:43, 48.73it/s]\u001b[A\n",
      "  1%|          | 48/5062 [00:00<01:40, 49.87it/s]\u001b[A\n",
      "  1%|          | 54/5062 [00:01<01:41, 49.18it/s]\u001b[A\n",
      "  1%|          | 60/5062 [00:01<01:46, 47.13it/s]\u001b[A\n",
      "  1%|▏         | 68/5062 [00:01<01:45, 47.52it/s]\u001b[A\n",
      "  2%|▏         | 77/5062 [00:01<01:40, 49.85it/s]\u001b[A\n",
      "  2%|▏         | 83/5062 [00:01<01:41, 49.17it/s]\u001b[A\n",
      "  2%|▏         | 90/5062 [00:01<01:40, 49.55it/s]\u001b[A\n",
      "  2%|▏         | 96/5062 [00:01<01:40, 49.36it/s]\u001b[A\n",
      "  2%|▏         | 103/5062 [00:02<01:38, 50.32it/s]\u001b[A\n",
      "  2%|▏         | 110/5062 [00:02<01:37, 50.74it/s]\u001b[A\n",
      "  2%|▏         | 116/5062 [00:02<01:38, 50.30it/s]\u001b[A\n",
      "  2%|▏         | 124/5062 [00:02<01:35, 51.44it/s]\u001b[A\n",
      "  3%|▎         | 132/5062 [00:02<01:33, 52.51it/s]\u001b[A\n",
      "  3%|▎         | 143/5062 [00:02<01:30, 54.18it/s]\u001b[A\n",
      "  3%|▎         | 152/5062 [00:02<01:29, 55.10it/s]\u001b[A\n",
      "  3%|▎         | 163/5062 [00:02<01:26, 56.86it/s]\u001b[A\n",
      "  3%|▎         | 174/5062 [00:02<01:24, 58.19it/s]\u001b[A\n",
      "  4%|▎         | 186/5062 [00:03<01:21, 59.92it/s]\u001b[A\n",
      "Exception in thread Thread-4:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib64/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home1/irteam/user/insikk/bow_image_retrieval/venv/lib64/python3.6/site-packages/tqdm/_tqdm.py\", line 144, in run\n",
      "    for instance in self.tqdm_cls._instances:\n",
      "  File \"/usr/lib64/python3.6/_weakrefset.py\", line 60, in __iter__\n",
      "    for itemref in self.data:\n",
      "RuntimeError: Set changed size during iteration\n",
      "\n",
      "100%|██████████| 5062/5062 [01:20<00:00, 62.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total num_descriptors: 13516675\n",
      "avg num_descriptors: 2670.2242196760176\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from multiprocessing import Pool, TimeoutError\n",
    "\n",
    "SIFT_DIR = \"./data/oxford5k_hesaff_sift\"\n",
    "output_image_descriptor_name = 'image_descriptor_dict_oxc5k_extracted_hesaff_sift'\n",
    "\n",
    "\n",
    "def sift_to_rootsift(descs):\n",
    "        if descs.dtype != np.float:\n",
    "            descs = descs.astype(np.float32)\n",
    "        # apply the Hellinger kernel by first L1-normalizing and taking the\n",
    "        # square-root\n",
    "        eps = 1e-10\n",
    "        l1_norm = np.linalg.norm(descs, 1)\n",
    "        descs /= (l1_norm + eps)\n",
    "        descs = np.sqrt(descs)\n",
    "        return descs\n",
    "    \n",
    "def parse_sift_output(target_path):\n",
    "    \"\"\"\n",
    "    Return:\n",
    "        kp: keypoint of hessian affine descriptor. location, orientation etc... OpenCV KeyPoint format. \n",
    "        des: 128d uint8 np array\n",
    "    \"\"\"    \n",
    "    kp = []\n",
    "    des = []\n",
    "    with open(target_path, \"r\") as f:\n",
    "        lines = list(map(lambda x: x.strip(), f.readlines()))\n",
    "        num_descriptor = int(lines[1])\n",
    "        lines = lines[2:]\n",
    "        for i in range(num_descriptor):\n",
    "            # print(i, lines[i])\n",
    "            val = lines[i].split(\" \")\n",
    "            x = float(val[0])\n",
    "            y = float(val[1])\n",
    "            a = float(val[2])\n",
    "            b = float(val[3])\n",
    "            c = float(val[4])\n",
    "            # TODO: generate ellipse shaped key point\n",
    "            # Refer: https://math.stackexchange.com/questions/1447730/drawing-ellipse-from-eigenvalue-eigenvector\n",
    "            # Refer: http://www.robots.ox.ac.uk/~vgg/research/affine/det_eval_files/display_features.m\n",
    "            # Refer: http://www.robots.ox.ac.uk/~vgg/research/affine/detectors.html\n",
    "            # key_point = cv2.KeyPoint(x, y, 1)\n",
    "            key_point = [x, y, a ,b, c]\n",
    "            sift_descriptor = np.array(list(map(lambda x: int(x), val[5:])), dtype=np.uint8)\n",
    "            rootSIFT = sift_to_rootsift(sift_descriptor)\n",
    "            kp.append(key_point)\n",
    "            des.append(rootSIFT)\n",
    "        \n",
    "    \n",
    "    return np.array(kp, dtype=np.float32), np.array(des)\n",
    "\n",
    "\n",
    "\n",
    "filelist = os.listdir(SIFT_DIR)\n",
    "\n",
    "image_descriptor_dict = {}\n",
    "\n",
    "num_descriptors = 0\n",
    "\n",
    "def run(filename):\n",
    "    filepath = os.path.join(SIFT_DIR, filename)\n",
    "    kp, des = parse_sift_output(filepath)\n",
    "    return (filename, (kp, des))\n",
    "\n",
    "pool = Pool(processes=20) # start 20 worker processes\n",
    "# print same numbers in arbitrary order\n",
    "for filename, tup in tqdm(pool.imap_unordered(run, filelist), total=len(filelist)):\n",
    "    image_descriptor_dict[filename.replace(\".jpg.hesaff.sift\", \"\")] =  tup\n",
    "    num_descriptors += tup[1].shape[0]\n",
    "    \n",
    "print(\"total num_descriptors:\", num_descriptors)\n",
    "print(\"avg num_descriptors:\", num_descriptors / len(filelist))\n",
    "    \n",
    "with open(output_image_descriptor_name + \"_{}M.pkl\".format(num_descriptor//1000000), 'wb') as f:\n",
    "    pickle.dump(image_descriptor_dict, f)\n",
    "print(\"done\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
